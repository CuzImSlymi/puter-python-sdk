{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Puter Python SDK\n",
    "\n",
    "Welcome to the Puter Python SDK! This notebook will guide you through the basics of using free AI models through the Puter.js platform.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- âœ… How to install and set up the SDK\n",
    "- âœ… Authentication with Puter.js\n",
    "- âœ… Basic chat functionality\n",
    "- âœ… Model switching and comparison\n",
    "- âœ… Async operations for better performance\n",
    "- âœ… Error handling best practices\n",
    "\n",
    "Let's get started! ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "First, let's install the Puter Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the SDK (run this if you haven't already)\n",
    "!pip install puter-python-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import and Setup\n",
    "\n",
    "Import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from puter import PuterAI, config\n",
    "\n",
    "print(\"âœ… Puter SDK imported successfully!\")\n",
    "print(f\"ğŸ“¦ SDK Version: 0.2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Authentication\n",
    "\n",
    "Set up your Puter.js credentials. You can either:\n",
    "1. Set environment variables `PUTER_USERNAME` and `PUTER_PASSWORD`\n",
    "2. Pass credentials directly to the client\n",
    "\n",
    "**Note:** Replace the placeholder credentials below with your actual Puter.js account details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using environment variables (recommended)\n",
    "# os.environ['PUTER_USERNAME'] = 'your_username'\n",
    "# os.environ['PUTER_PASSWORD'] = 'your_password'\n",
    "\n",
    "# Method 2: Direct credentials (update these with your actual credentials)\n",
    "USERNAME = \"your_username_here\"  # Replace with your Puter.js username\n",
    "PASSWORD = \"your_password_here\"  # Replace with your Puter.js password\n",
    "\n",
    "# Check if credentials are set\n",
    "if USERNAME == \"your_username_here\":\n",
    "    print(\"âš ï¸ Please update the credentials above with your actual Puter.js account details!\")\n",
    "else:\n",
    "    print(\"âœ… Credentials configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Client and Login\n",
    "\n",
    "Create a PuterAI client and authenticate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = PuterAI(username=USERNAME, password=PASSWORD)\n",
    "\n",
    "# Login to Puter.js\n",
    "try:\n",
    "    print(\"ğŸ” Logging in...\")\n",
    "    success = client.login()\n",
    "    if success:\n",
    "        print(\"âœ… Successfully logged in to Puter.js!\")\n",
    "    else:\n",
    "        print(\"âŒ Login failed\")\nexcept Exception as e:\n",
    "    print(f\"âŒ Login error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Explore Available Models\n",
    "\n",
    "Let's see what AI models are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all available models\n",
    "models = client.get_available_models()\n",
    "\n",
    "print(f\"ğŸ¤– Total available models: {len(models)}\")\n",
    "print(f\"ğŸ¯ Current model: {client.current_model}\")\n",
    "\n",
    "# Show some popular models\n",
    "popular_models = [\n",
    "    \"gpt-4o\", \"claude-3.5-sonnet\", \"gpt-4\", \"claude-opus-4\", \n",
    "    \"gemini-pro\", \"llama-3.1-70b\", \"gpt-3.5-turbo\"\n",
    "]\n",
    "\n",
    "available_popular = [m for m in popular_models if m in models]\n",
    "\n",
    "print(\"\\nğŸŒŸ Popular models available:\")\n",
    "for model in available_popular[:5]:\n",
    "    print(f\"  â€¢ {model}\")\n",
    "\n",
    "if len(available_popular) > 5:\n",
    "    print(f\"  ... and {len(available_popular) - 5} more!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Your First AI Chat\n",
    "\n",
    "Let's have a simple conversation with the AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chat example\n",
    "prompt = \"Hello! Explain what you are in one sentence.\"\n",
    "\n",
    "print(f\"ğŸ‘¤ User: {prompt}\")\n",
    "print(\"ğŸ¤– AI: \", end=\"\")\n",
    "\n",
    "try:\n",
    "    response = client.chat(prompt)\n",
    "    print(response)\nexcept Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Multi-turn Conversation\n",
    "\n",
    "The SDK automatically manages conversation history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-turn conversation\n",
    "questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"Can you give me a simple example?\",\n",
    "    \"What programming languages are best for it?\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ’¬ Multi-turn conversation:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n[Turn {i}]\")\n",
    "    print(f\"ğŸ‘¤ User: {question}\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat(question)\n",
    "        # Truncate for display\n",
    "        display_response = response[:200] + \"...\" if len(response) > 200 else response\n",
    "        print(f\"ğŸ¤– AI: {display_response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ“š Conversation history length: {len(client.chat_history)} messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Switching\n",
    "\n",
    "Let's try the same question with different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test question\n",
    "test_question = \"Write a haiku about artificial intelligence.\"\n",
    "\n",
    "# Models to test\n",
    "test_models = [\"gpt-4\", \"claude-3.5-sonnet\", \"gpt-3.5-turbo\"]\n",
    "available_test_models = [m for m in test_models if m in models]\n",
    "\n",
    "if not available_test_models:\n",
    "    available_test_models = models[:3]  # Use first 3 available models\n",
    "\n",
    "print(f\"ğŸ”„ Testing question with different models:\")\n",
    "print(f\"â“ Question: {test_question}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for model in available_test_models:\n",
    "    try:\n",
    "        # Switch model and clear history for fair comparison\n",
    "        client.set_model(model)\n",
    "        client.clear_chat_history()\n",
    "        \n",
    "        print(f\"\\nğŸ¤– {model}:\")\n",
    "        response = client.chat(test_question)\n",
    "        print(response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {model}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Async Operations\n",
    "\n",
    "For better performance, especially when making multiple requests, use async operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def async_demo():\n",
    "    \"\"\"Demonstrate async operations.\"\"\"\n",
    "    \n",
    "    # Create a new client for async operations\n",
    "    async_client = PuterAI(username=USERNAME, password=PASSWORD)\n",
    "    \n",
    "    try:\n",
    "        # Async login\n",
    "        print(\"ğŸ” Async login...\")\n",
    "        await async_client.async_login()\n",
    "        print(\"âœ… Logged in asynchronously!\")\n",
    "        \n",
    "        # Multiple concurrent requests\n",
    "        questions = [\n",
    "            \"What is Python?\",\n",
    "            \"What is JavaScript?\", \n",
    "            \"What is machine learning?\",\n",
    "            \"What is blockchain?\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"\\nğŸš€ Running {len(questions)} questions concurrently...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Create tasks for concurrent execution\n",
    "        tasks = [async_client.async_chat(q) for q in questions]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"âš¡ Completed in {end_time - start_time:.2f} seconds\")\n",
    "        \n",
    "        # Display results\n",
    "        for question, response in zip(questions, responses):\n",
    "            print(f\"\\nâ“ {question}\")\n",
    "            display_response = response[:100] + \"...\" if len(response) > 100 else response\n",
    "            print(f\"ğŸ’¡ {display_response}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Async error: {e}\")\n",
    "\n",
    "# Run the async demo\n",
    "await async_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Configuration and Advanced Features\n",
    "\n",
    "Explore the configuration options and advanced features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check current configuration\n",
    "print(\"âš™ï¸ Current Configuration:\")\n",
    "print(f\"â€¢ API Base: {config.api_base}\")\n",
    "print(f\"â€¢ Timeout: {config.timeout}s\")\n",
    "print(f\"â€¢ Max Retries: {config.max_retries}\")\n",
    "print(f\"â€¢ Rate Limit: {config.rate_limit_requests}/{config.rate_limit_period}s\")\n",
    "\n",
    "# Create a client with custom configuration\n",
    "print(\"\\nğŸ”§ Creating client with custom settings...\")\n",
    "custom_client = PuterAI(\n",
    "    username=USERNAME,\n",
    "    password=PASSWORD,\n",
    "    timeout=60,  # 60 second timeout\n",
    "    max_retries=5,  # 5 retry attempts\n",
    "    rate_limit_requests=20,  # 20 requests per period\n",
    "    rate_limit_period=60  # per 60 seconds\n",
    ")\n",
    "\n",
    "print(\"âœ… Custom client created with enhanced settings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Error Handling Best Practices\n",
    "\n",
    "Learn how to handle errors gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from puter import PuterAuthError, PuterAPIError\n",
    "\n",
    "def robust_chat(client, prompt, max_retries=3):\n",
    "    \"\"\"A robust chat function with error handling.\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.chat(prompt)\n",
    "            return response\n",
    "            \n",
    "        except PuterAuthError as e:\n",
    "            print(f\"ğŸ” Authentication error: {e}\")\n",
    "            print(\"Please check your credentials and try logging in again.\")\n",
    "            return None\n",
    "            \n",
    "        except PuterAPIError as e:\n",
    "            print(f\"ğŸŒ API error (attempt {attempt + 1}/{max_retries}): {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"âŒ Max retries reached. Please try again later.\")\n",
    "                return None\n",
    "            else:\n",
    "                print(\"ğŸ”„ Retrying...\")\n",
    "                time.sleep(2)  # Wait before retry\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Unexpected error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Test the robust chat function\n",
    "print(\"ğŸ›¡ï¸ Testing robust error handling:\")\n",
    "response = robust_chat(client, \"What is the future of AI?\")\n",
    "\n",
    "if response:\n",
    "    print(f\"âœ… Success: {response[:100]}...\")\nelse:\n",
    "    print(\"âŒ Failed to get response\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Congratulations!\n",
    "\n",
    "You've successfully learned the basics of the Puter Python SDK! Here's what you've accomplished:\n",
    "\n",
    "âœ… **Installed and set up** the SDK  \n",
    "âœ… **Authenticated** with Puter.js  \n",
    "âœ… **Chatted with AI** models  \n",
    "âœ… **Switched between models** for comparison  \n",
    "âœ… **Used async operations** for better performance  \n",
    "âœ… **Handled errors** gracefully  \n",
    "\n",
    "## ğŸš€ Next Steps\n",
    "\n",
    "Now that you know the basics, explore more advanced examples:\n",
    "\n",
    "- ğŸ¤– **[Simple Chatbot](../chatbots/simple_chatbot.py)** - Build interactive chatbots\n",
    "- âœï¸ **[Blog Writer](../content_generation/blog_writer.py)** - Generate content automatically\n",
    "- âš¡ **[Batch Processing](../workflows/batch_processing.py)** - Process multiple tasks efficiently\n",
    "- ğŸ”„ **[Model Comparison](model_comparison.ipynb)** - Compare different AI models\n",
    "\n",
    "## ğŸ“š Resources\n",
    "\n",
    "- ğŸ“– [Full Documentation](../../README.md)\n",
    "- ğŸ› [Report Issues](https://github.com/CuzImSlymi/puter-python-sdk/issues)\n",
    "- ğŸ’¬ [Join Discussions](https://github.com/CuzImSlymi/puter-python-sdk/discussions)\n",
    "\n",
    "Happy coding! ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
